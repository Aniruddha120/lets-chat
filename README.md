# Let's ChatðŸ’¬ - A Chatbot Powered by PaLM API

## Table of Contents
- [Introduction](#introduction)
- [Features](#features)
- [Getting Started](#getting-started)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
- [Usage](#usage)
  - [Running Let's Chat](#running-lets-chat)
- [Why PaLM API?](#Why PaLM API?)

## Introduction

"Let's ChatðŸ’¬" is a chatbot powered by the Bard API, designed to make conversations with AI more engaging and interactive. Whether you want a casual chat or use it for a specific purpose, "Let's Chat" aims to provide a seamless and enjoyable experience.

Preview: https://huggingface.co/spaces/Aniruddha120/lets-chat 

## Features

- Natural language understanding and generation.
- Customizable responses and conversations.
- Integration with the Bard API for advanced language capabilities.
- Easy-to-use chat interface.

## Getting Started

### Prerequisites

Before you begin, ensure you have met the following requirements:

- Python 3.7 or higher installed.
- Access to the Bard API (you'll need API credentials).

### Installation

1. Clone the repository:

   ```sh
   git clone https://github.com/Aniruddha120/lets-chat.git
   cd lets-chat

2. Install the required Python dependencies:

    pip install -r requirements.txt
   
### Usage

For API key, you can hard code the API key or create a TOML file to store your streamlit secret files. 

Running Let's Chat

To start "Let's Chat," run the following command:

    streamlit run app.py

### Why PaLM API?

It's free, easy to use, and Powerful.

For free per number of token fees, the name of the model that came into my mind was LLAMA-2. But, it must be hosted in a cloud server and will charge fees. There is currently no free option to get LLAMA via API. But PaLM can be accessed via API without any charges. 
   
